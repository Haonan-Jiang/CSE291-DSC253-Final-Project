{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0      1                                                  2\n",
      "0  Tweet index  Label                                         Tweet text\n",
      "1            1      1  Sweet United Nations video. Just in time for C...\n",
      "2            2      1  @mrdahl87 We are rumored to have talked to Erv...\n",
      "3            3      1  Hey there! Nice to see you Minnesota/ND Winter...\n",
      "4            4      0                3 episodes left I'm dying over here\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "5    1\n",
      "Name: 1, dtype: object\n",
      "1    Sweet United Nations video. Just in time for C...\n",
      "2    @mrdahl87 We are rumored to have talked to Erv...\n",
      "3    Hey there! Nice to see you Minnesota/ND Winter...\n",
      "4                  3 episodes left I'm dying over here\n",
      "5    I can't breathe! was chosen as the most notabl...\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "# load from txt file\n",
    "datapath = 'dataset/irony'\n",
    "df = pd.read_csv(datapath+'/SemEval2018-T3-train-taskA.txt', sep='\\t', header=None)\n",
    "print(df.head())\n",
    "labels = df[1]\n",
    "texts = df[2]\n",
    "# remove the first row in labels and texts\n",
    "labels = labels[1:]\n",
    "texts = texts[1:]\n",
    "print(labels.head())\n",
    "print(texts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learn from various samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Samples:\n",
      "Here are five tweet samples that aim to present unique challenges and cover a diverse range of scenarios:\n",
      "\n",
      "**Sample 1: Double Meaning**\n",
      "\"Just got my period... I mean, just got my package delivered! #newkitchenware\" (Ironic)\n",
      "\n",
      "This sample is designed to test the model's ability to recognize double meanings. The phrase \"got my period\" can refer to both menstruation and receiving a delivery, making it essential for the model to consider the context and intent behind the tweet.\n",
      "\n",
      "**Sample 2: Sarcastic Statement**\n",
      "\"I'm so excited to be stuck in this traffic jam! Who needs to get to work on time, anyway? #rushhourblues\" (Ironic)\n",
      "\n",
      "This sample is meant to challenge the model's ability to detect sarcasm. The statement \"so excited\" is clearly meant to convey the opposite emotion, and the model must recognize the tone as playful rather than genuine.\n",
      "\n",
      "**Sample 3: Hyperbole**\n",
      "\"Just ran a marathon... in my backyard! I'm basically an Olympic athlete now! #fitnessgoals\" (Not Ironic)\n",
      "\n",
      "This sample aims to test the model's ability to distinguish between exaggeration and irony. While the statement is clearly hyperbolic, it doesn't contain any obvious ironic markers, making it necessary for the model to consider the context and the speaker's intentions.\n",
      "\n",
      "**Sample 4: Subtle Humor**\n",
      "\"I love how my cat thinks she owns the place... even when I'm trying to sleep in! #felineoverlords\" (Ironic)\n",
      "\n",
      "This sample is designed to challenge the model's ability to recognize subtle humor. The tweet may not explicitly state that it's ironic, but the speaker's tone and the absurdity of the situation should give away their intention.\n",
      "\n",
      "**Sample 5: Misdirection**\n",
      "\"I'm so glad I don't have to deal with rush hour traffic anymore... since I've been working from home for months now! #WFHlife\" (Not Ironic)\n",
      "\n",
      "This sample is meant to test the model's ability to resist misdirection. The statement \"so glad\" seems positive, but it's actually a straightforward expression of relief rather than irony. The model must ignore the initial tone and focus on the speaker's actual sentiment.\n",
      "\n",
      "These samples aim to provide a diverse set of challenges for the task, from double meanings and sarcasm to hyperbole and subtle humor.\n",
      "Analysis of Samples:\n",
      "Based on the provided samples, I've derived general principles for classifying tweets as 'ironic' or 'not ironic'. Here are the key takeaways:\n",
      "\n",
      "**General Principles:**\n",
      "\n",
      "* **Ironic Tweets:**\n",
      "\t+ Typically contain language that is intentionally contrary to the literal meaning.\n",
      "\t+ May use sarcasm, understatement, or overstatement to convey irony.\n",
      "\t+ Often rely on shared knowledge or cultural references to create the ironic effect.\n",
      "\t+ Can be subtle and require close reading to detect.\n",
      "* **Not Ironic Tweets:**\n",
      "\t+ Typically convey a straightforward or genuine sentiment.\n",
      "\t+ May use hyperbole, exaggeration, or colloquialisms, but these should not be mistaken for irony.\n",
      "\t+ Do not rely on shared knowledge or cultural references to create the effect.\n",
      "\n",
      "**Common Mistakes and How to Avoid Them:**\n",
      "\n",
      "* **Overlooking Context:** Don't assume a tweet is ironic just because it contains a phrase that could be interpreted as ironic. Consider the entire tweet, including surrounding language, tone, and cultural context.\n",
      "* **Misinterpreting Tone:** Be cautious of tweets with a sarcastic or playful tone, as these can often be misinterpreted as ironic. Instead, focus on the speaker's intended meaning and the literal content of the tweet.\n",
      "* **Ignoring Intent:** Don't assume a tweet is ironic just because it contains an unexpected twist. Consider the speaker's intent behind the tweet and whether it's meant to be humorous or thought-provoking.\n",
      "\n",
      "**Guidelines:**\n",
      "\n",
      "* **Categorize as Ironic:**\n",
      "\t+ If a tweet contains language that intentionally contradicts its literal meaning.\n",
      "\t+ If a tweet relies on shared knowledge, cultural references, or subtlety to create an ironic effect.\n",
      "\t+ If the tone of the tweet is playful, sarcastic, or humorous, and it's clear that the speaker intended to be ironic.\n",
      "* **Categorize as Not Ironic:**\n",
      "\t+ If a tweet conveys a straightforward or genuine sentiment without intentionally contradictory language.\n",
      "\t+ If the tone of the tweet is serious, informative, or literal, indicating no intention to be ironic.\n",
      "\t+ If the tweet relies on exaggeration, hyperbole, or colloquialisms, but these are not meant to create an ironic effect.\n",
      "\n",
      "By following these principles and guidelines, you can accurately classify tweets as 'ironic' or 'not ironic' based solely on their content.\n",
      "Optimized Prompt:\n",
      "Predict whether a tweet is 'ironic' or 'not ironic' based on its content, considering the following criteria:\n",
      "\n",
      "Classify as 'ironic' if:\n",
      "* The tweet contains language intentionally contrary to its literal meaning.\n",
      "* The tweet relies on shared knowledge, cultural references, or subtlety to create an ironic effect.\n",
      "* The tone of the tweet is playful, sarcastic, or humorous and it's clear that the speaker intended to be ironic.\n",
      "\n",
      "Classify as 'not ironic' if:\n",
      "* The tweet conveys a straightforward or genuine sentiment without intentionally contradictory language.\n",
      "* The tone of the tweet is serious, informative, or literal indicating no intention to be ironic.\n",
      "* Exaggeration, hyperbole, or colloquialisms are used, but not intended to create an ironic effect.\n",
      "\n",
      "Avoid misclassifying by considering:\n",
      "* The entire tweet, including surrounding language, tone, and cultural context.\n",
      "* The speaker's intent behind the tweet and whether it's meant to be humorous or thought-provoking.\n",
      "\n",
      "Respond with only 'ironic' or 'not ironic'.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# Function to interact with the Ollama API\n",
    "def chat_with_context(history):\n",
    "    response = ollama.chat(model='llama3', messages=history)\n",
    "    return response['message']['content']\n",
    "\n",
    "# Initialize the chat history\n",
    "chat_history = []\n",
    "\n",
    "# Step 1: Generate Correctly Classified and Misclassified Samples\n",
    "num_samples = 5\n",
    "task_description = \"We need to predict whether a given tweet is ironic or not. The labels are 'ironic' and 'not ironic'.\"\n",
    "\n",
    "generate_samples_request = (\n",
    "    f\"As an advanced language model you should create {num_samples} samples for the task outlined below.\\n\"\n",
    "    \"Generate samples that are likely to be correctly classified as 'ironic' or 'not ironic' and samples that might be misclassified according to the task instructions.\\n\\n\"\n",
    "    f\"### Task Description:\\n{task_description}\\n\\n\"\n",
    "    \"### Requirements for Samples:\\n\"\n",
    "    \"1. Each sample must present a unique and intricate challenge.\\n\"\n",
    "    \"2. The complexity of the samples should be such that simply applying the given task instruction would likely lead to incorrect or incomplete results for some samples.\\n\"\n",
    "    \"3. The samples should cover a diverse range of scenarios within the scope of the task, avoiding repetition and predictability.\\n\"\n",
    "    \"4. Ensure that the samples, while challenging, remain realistic and pertinent to the task's context.\\n\"\n",
    "    \"Generate the samples keeping these requirements in mind.\\n###\"\n",
    ")\n",
    "\n",
    "chat_history.append({'role': 'user', 'content': task_description})\n",
    "chat_history.append({'role': 'user', 'content': generate_samples_request})\n",
    "\n",
    "samples_response = chat_with_context(chat_history)\n",
    "chat_history.append({'role': 'assistant', 'content': samples_response})\n",
    "print(\"Generated Samples:\")\n",
    "print(samples_response)\n",
    "\n",
    "# Step 2: Analyze Samples with Chain of Thought\n",
    "analyze_samples_request = (\n",
    "    f\"Here are some samples: {samples_response}\\n\"\n",
    "    \"Think step by step and derive general principles for classifying tweets as 'ironic' or 'not ironic'.\\n\"\n",
    "    \"Avoid focusing on specific details of the provided samples. Instead, develop broader, example-agnostic guidelines that can be applied universally to classify any news article. Conclude your analysis with clear, concise bullet points outlining:\\n\"\n",
    "    \"- The general characteristics that typically define each category.\\n\"\n",
    "    \"- Common mistakes that might lead to misclassifications and how to avoid them.\\n\"\n",
    "    \"- Guidelines under which circumstances each label should be predicted.\\n\"\n",
    "    \"These principles should help in accurately predicting the category of a tweet based on its content without additional context.\"\n",
    ")\n",
    "\n",
    "chat_history.append({'role': 'user', 'content': analyze_samples_request})\n",
    "\n",
    "analysis_response = chat_with_context(chat_history)\n",
    "chat_history.append({'role': 'assistant', 'content': analysis_response})\n",
    "print(\"Analysis of Samples:\")\n",
    "print(analysis_response)\n",
    "\n",
    "# Step 3: Generate Optimized Prompt\n",
    "generate_prompt_request = (\n",
    "    f\"Based on the following analysis: {analysis_response}\\nGenerate an optimized prompt for predicting \"\n",
    "    \"whether a tweet is 'ironic' or 'not ironic'. Ensure the model responds only with 'ironic' or 'not ironic'.\\n\\n\"\n",
    "    \"### Requirements for Optimized Prompt:\\n\"\n",
    "    \"1. The prompt must include a clear description of the task and the labels.\\n\"\n",
    "    \"2. It should provide criteria for classifying tweets as 'ironic' or 'not ironic' based on the analysis.\\n\"\n",
    "    \"3. The prompt must ensure that the model responds strictly with 'ironic' or 'not ironic'.\\n\"\n",
    "    \"4. The prompt should help the model avoid common pitfalls and misclassifications identified during the analysis.\\n\"\n",
    "    \"5. Ensure the language is unambiguous and tailored to maximize the model's prediction accuracy.\\n\"\n",
    "    \"6. Encourage the model to think step by step.\\n\"\n",
    "    \"Respond with no other explanation but only the content of the prompt that is ready for the model to predict\\n\"\n",
    "    \"Prompt:\"\n",
    ")\n",
    "\n",
    "chat_history.append({'role': 'user', 'content': generate_prompt_request})\n",
    "\n",
    "optimized_prompt_response = chat_with_context(chat_history)\n",
    "chat_history.append({'role': 'assistant', 'content': optimized_prompt_response})\n",
    "print(\"Optimized Prompt:\")\n",
    "print(optimized_prompt_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting tweet 1 out of 3817\n",
      "Predicting tweet 1001 out of 3817\n",
      "Predicting tweet 2001 out of 3817\n",
      "Predicting tweet 3001 out of 3817\n",
      "Model Accuracy: 0.5441446161907257\n"
     ]
    }
   ],
   "source": [
    "def get_prediction(text):\n",
    "    prompt = (\n",
    "        f\"{optimized_prompt_response}\\n\\n\"\n",
    "        f\"Tweet: {text}\\n\\n\"\n",
    "        \"### Requirements:\\n\"\n",
    "        \"1. Respond with only a single-digit (0 for not ironic, 1 for ironic).\\n\"\n",
    "        \"2. Do not provide any additional text or explanation.\\n\"\n",
    "        \"Respond with only '0' or '1':\"\n",
    "    )\n",
    "    response = ollama.generate(model='llama3', prompt=prompt)\n",
    "    # Ensure the response is either '0' or '1'\n",
    "    response_text = response['response'].strip()\n",
    "    if '1' in response_text:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "predictions = []\n",
    "for i, text in enumerate(texts):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Predicting tweet {i+1} out of {len(texts)}\")\n",
    "    # if i == 1000:\n",
    "    #     break\n",
    "    prediction = get_prediction(text)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# Step 6: Evaluate Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "predictions = [\"1\" if \"1\" in p else \"0\" for p in predictions]\n",
    "accuracy = accuracy_score(labels[:len(predictions)], predictions)\n",
    "print(f\"Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With zero shot COT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting tweet 1 out of 3817\n",
      "Predicting tweet 1001 out of 3817\n",
      "Predicting tweet 2001 out of 3817\n",
      "Predicting tweet 3001 out of 3817\n",
      "Model Accuracy: 0.5375949698716269\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "def get_prediction(text):\n",
    "    prompt = (\n",
    "        \"Predict whether the following tweet is ironic or not:\\n\\n\"\n",
    "        \"Let's think step by step\"\n",
    "        f\"Tweet: {text}\\n\\n\"\n",
    "        \"### Requirements:\\n\"\n",
    "        \"1. Respond with only a single-digit (0 for not ironic, 1 for ironic).\\n\"\n",
    "        \"2. Do not provide any additional text or explanation.\\n\"\n",
    "        \"Respond with only '0' or '1':\"\n",
    "    )\n",
    "    response = ollama.generate(model='llama3', prompt=prompt)\n",
    "    # Ensure the response is either '0' or '1'\n",
    "    response_text = response['response'].strip()\n",
    "    if '1' in response_text:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "predictions = []\n",
    "for i, text in enumerate(texts):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Predicting tweet {i+1} out of {len(texts)}\")\n",
    "    # if i == 1000:\n",
    "    #     break\n",
    "    prediction = get_prediction(text)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# Step 6: Evaluate Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "predictions = [\"1\" if \"1\" in p else \"0\" for p in predictions]\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "print(f\"Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# with basic prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting tweet 1 out of 3817\n",
      "Predicting tweet 1001 out of 3817\n",
      "Predicting tweet 2001 out of 3817\n",
      "Predicting tweet 3001 out of 3817\n",
      "Model Accuracy: 0.48388787005501704\n"
     ]
    }
   ],
   "source": [
    "def get_prediction(text):\n",
    "    response = ollama.generate(model='llama3', prompt=f\"Predict if the tweet text is ironic or not: {text}. make sure to respond with only the prediction value (0 or 1)\")\n",
    "    return response['response']\n",
    "\n",
    "predictions = []\n",
    "for i, text in enumerate(texts):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Predicting tweet {i+1} out of {len(texts)}\")\n",
    "    prediction = get_prediction(text)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# Step 6: Evaluate Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "print(f\"Model Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# few shot prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting tweet 1001 out of 3817\n",
      "Predicting tweet 2001 out of 3817\n",
      "Predicting tweet 3001 out of 3817\n",
      "Model Accuracy: 0.4884635553224961\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "datapath = 'dataset/irony'\n",
    "df = pd.read_csv(datapath+'/SemEval2018-T3-train-taskA.txt', sep='\\t', header=None)\n",
    "labels = df[1][1:]\n",
    "texts = df[2][1:]\n",
    "\n",
    "# construct few shot learning task\n",
    "few_shot_text = texts[:3]\n",
    "few_shot_labels = labels[:3]\n",
    "\n",
    "\n",
    "\n",
    "# Function to interact with the Ollama API\n",
    "def get_prediction(text):\n",
    "    # use the first few samples as few shot learning examples\n",
    "    prompt = (f\"Here are the first few tweets in the dataset:\\n\\n1. {few_shot_text.iloc[0]} label:{few_shot_labels.iloc[0]}\\n2. {few_shot_text.iloc[1]} label:{few_shot_labels.iloc[1]}\\n3. {few_shot_text.iloc[2]} label:{few_shot_labels.iloc[2]}\\n\\n\"\n",
    "            \"Based on these examples, predict whether the following tweet is ironic or not:\"\n",
    "            f\"Tweet: {text}\\n\\n\"\n",
    "            \"### Requirements:\\n\"\n",
    "            \"1. Respond with only a single-digit (0 for not ironic, 1 for ironic).\\n\"\n",
    "            \"2. Do not provide any additional text or explanation.\\n\"\n",
    "            \"Respond with only '0' or '1':\"\n",
    "    )\n",
    "    response = ollama.generate(model='llama3', prompt=prompt)\n",
    "    # Ensure the response is either '0' or '1'\n",
    "    response_text = response['response'].strip()\n",
    "    if '1' in response_text:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "    \n",
    "# Make predictions\n",
    "predictions = []\n",
    "for i, text in enumerate(texts):\n",
    "    if i == 0 or i == 1 or i == 2:\n",
    "        continue\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Predicting tweet {i+1} out of {len(texts)}\")\n",
    "    prediction = get_prediction(text)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# Step 6: Evaluate Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(labels[3:], predictions)\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# two step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Samples:\n",
      "Here are 5 samples for the irony detection task:\n",
      "\n",
      "**Sample 1:** \"Just got a promotion! Now I can finally relax on Fridays and watch Netflix all day.\" (Label: 'ironic')\n",
      "\n",
      "This sample is likely to be correctly classified as ironic because it presents an unexpected twist on the typical reaction to getting a promotion. The speaker's tone seems to convey sarcasm, implying that they are not actually looking forward to relaxing on Fridays.\n",
      "\n",
      "**Sample 2:** \"I'm so done with social media. It's all just noise and distraction.\" (Label: 'not ironic')\n",
      "\n",
      "This sample appears to be genuinely expressing frustration with social media, without any apparent irony or sarcasm. The speaker seems to mean what they say, making it unlikely to be misclassified.\n",
      "\n",
      "**Sample 3:** \"Just spent the whole day shopping for new clothes and I'm still wearing my old favorites.\" (Label: 'ironic')\n",
      "\n",
      "This sample presents a contradictory statement that might lead to incorrect classification if not carefully analyzed. The speaker claims to have bought new clothes, but is still wearing their old favorites. This could be an ironic comment on the futility of consumerism or simply a humorous observation.\n",
      "\n",
      "**Sample 4:** \"The most epic game of chess I've ever played was the one I lost by a single pawn.\" (Label: 'ironic')\n",
      "\n",
      "This sample seems to use irony to highlight the unexpected nature of losing a game of chess, which is typically associated with victory and strategy. The speaker's tone appears to be tongue-in-cheek, making it likely to be classified as ironic.\n",
      "\n",
      "**Sample 5:** \"I'm really excited about this new diet I started... said no one ever.\" (Label: 'ironic')\n",
      "\n",
      "This sample uses a common phrase (\"said no one ever\") to signal that the speaker is being sarcastic. The statement itself is an ironic commentary on the challenges and unpopularity of diets, making it likely to be correctly classified as ironic.\n",
      "\n",
      "These samples are designed to present various challenges for the task, including unexpected twists, contradictions, and playful uses of language.\n",
      "Analysis of Samples:\n",
      "Here are the general principles for classifying tweets as 'ironic' or 'not ironic':\n",
      "\n",
      "**Characteristics that typically define each category:**\n",
      "\n",
      "* **Ironic:** Tweets that are ironic often exhibit one or more of the following characteristics:\n",
      "\t+ Contradictory statements (e.g., \"Just got a promotion! Now I can finally relax on Fridays...\")\n",
      "\t+ Unexpected twists or reversals (e.g., \"The most epic game of chess I've ever played was the one I lost by a single pawn.\")\n",
      "\t+ Playful uses of language (e.g., sarcasm, understatement, or exaggeration)\n",
      "\t+ Comments that are intentionally opposite of what is expected\n",
      "* **Not ironic:** Tweets that are not ironic typically lack these characteristics and instead:\n",
      "\t+ Express genuine emotions or opinions\n",
      "\t+ Present straightforward statements without unexpected twists\n",
      "\t+ Lack intentional language play (sarcasm, irony, etc.)\n",
      "\n",
      "**Common mistakes that might lead to misclassifications:**\n",
      "\n",
      "* Failing to consider the tone of the tweet: Pay attention to the speaker's intended meaning and tone.\n",
      "* Misinterpreting literal statements as ironic: Be cautious when evaluating straightforward statements without clear indication of irony.\n",
      "* Overlooking subtle cues: Look for subtle hints, such as word choice or punctuation, that might indicate irony.\n",
      "\n",
      "**Guidelines under which circumstances each label should be predicted:**\n",
      "\n",
      "* **Ironic:** Predict 'ironic' when:\n",
      "\t+ The tweet contains a contradictory statement or unexpected twist\n",
      "\t+ The speaker's tone suggests sarcasm, playfulness, or irony\n",
      "\t+ The tweet's content is intentionally opposite of what is expected\n",
      "* **Not ironic:** Predict 'not ironic' when:\n",
      "\t+ The tweet expresses genuine emotions or opinions without any apparent irony\n",
      "\t+ The statement is straightforward and lacks unexpected twists or reversals\n",
      "\t+ The speaker's tone suggests sincerity or seriousness\n",
      "\n",
      "By considering these general principles, you can develop a more accurate understanding of what makes a tweet ironic or not, regardless of the specific context.\n",
      "Optimized Prompt:\n",
      "Classify this tweet as 'ironic' or 'not ironic': \n",
      "\n",
      "Predict whether a tweet is ironic or not based on its content. Consider the following criteria:\n",
      "\n",
      "* Is the tweet's statement contradictory, unexpected, or opposite of what is expected?\n",
      "* Does the speaker's tone convey sarcasm, playfulness, or irony? \n",
      "* Is the tweet's content intentionally humorous, exaggerated, or ironic?\n",
      "\n",
      "Avoid misclassifying tweets by considering the following:\n",
      "* Failing to consider the tone and intended meaning of the tweet\n",
      "* Misinterpreting literal statements as ironic\n",
      "* Overlooking subtle cues that indicate irony\n",
      "\n",
      "Classify this tweet as 'ironic' if it meets one or more of these criteria. Otherwise, classify it as 'not ironic'.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# Function to interact with the Ollama API\n",
    "def chat_with_context(history):\n",
    "    response = ollama.chat(model='llama3', messages=history)\n",
    "    return response['message']['content']\n",
    "\n",
    "# Initialize the chat history\n",
    "chat_history = []\n",
    "\n",
    "# Step 1: Generate Correctly Classified and Misclassified Samples\n",
    "num_samples = 5\n",
    "task_description = \"We need to predict whether a given tweet is ironic or not. The labels are 'ironic' and 'not ironic'.\"\n",
    "\n",
    "generate_samples_request = (\n",
    "    f\"As an advanced language model you should create {num_samples} samples for the task outlined below.\\n\"\n",
    "    \"Generate samples that are likely to be correctly classified as 'ironic' or 'not ironic' and samples that might be misclassified according to the task instructions.\\n\\n\"\n",
    "    f\"### Task Description:\\n{task_description}\\n\\n\"\n",
    "    \"### Requirements for Samples:\\n\"\n",
    "    \"1. Each sample must present a unique and intricate challenge.\\n\"\n",
    "    \"2. The complexity of the samples should be such that simply applying the given task instruction would likely lead to incorrect or incomplete results for some samples.\\n\"\n",
    "    \"3. The samples should cover a diverse range of scenarios within the scope of the task, avoiding repetition and predictability.\\n\"\n",
    "    \"4. Ensure that the samples, while challenging, remain realistic and pertinent to the task's context.\\n\"\n",
    "    \"Generate the samples keeping these requirements in mind.\\n###\"\n",
    ")\n",
    "\n",
    "chat_history.append({'role': 'user', 'content': task_description})\n",
    "chat_history.append({'role': 'user', 'content': generate_samples_request})\n",
    "\n",
    "samples_response = chat_with_context(chat_history)\n",
    "chat_history.append({'role': 'assistant', 'content': samples_response})\n",
    "print(\"Generated Samples:\")\n",
    "print(samples_response)\n",
    "\n",
    "# Step 2: Analyze Samples with Chain of Thought\n",
    "analyze_samples_request = (\n",
    "    f\"Here are some samples: {samples_response}\\n\"\n",
    "    \"Think step by step and derive general principles for classifying tweets as 'ironic' or 'not ironic'.\\n\"\n",
    "    \"Avoid focusing on specific details of the provided samples. Instead, develop broader, example-agnostic guidelines that can be applied universally to classify any news article. Conclude your analysis with clear, concise bullet points outlining:\\n\"\n",
    "    \"- The general characteristics that typically define each category.\\n\"\n",
    "    \"- Common mistakes that might lead to misclassifications and how to avoid them.\\n\"\n",
    "    \"- Guidelines under which circumstances each label should be predicted.\\n\"\n",
    "    \"These principles should help in accurately predicting the category of a tweet based on its content without additional context.\"\n",
    ")\n",
    "\n",
    "chat_history.append({'role': 'user', 'content': analyze_samples_request})\n",
    "\n",
    "analysis_response = chat_with_context(chat_history)\n",
    "chat_history.append({'role': 'assistant', 'content': analysis_response})\n",
    "print(\"Analysis of Samples:\")\n",
    "print(analysis_response)\n",
    "\n",
    "# Step 3: Generate Optimized Prompt\n",
    "generate_prompt_request = (\n",
    "    f\"Based on the following analysis: {analysis_response}\\nGenerate an optimized prompt for predicting \"\n",
    "    \"whether a tweet is 'ironic' or 'not ironic'.\\n\\n\"\n",
    "    \"### Requirements for Optimized Prompt:\\n\"\n",
    "    \"1. The prompt must include a clear description of the task and the labels.\\n\"\n",
    "    \"2. It should provide criteria for classifying tweets as 'ironic' or 'not ironic' based on the analysis.\\n\"\n",
    "    \"3. The prompt should help the model avoid common pitfalls and misclassifications identified during the analysis.\\n\"\n",
    "    \"4. Ensure the language is unambiguous and tailored to maximize the model's prediction accuracy.\\n\"\n",
    "    \"5. Encourage the model to think step by step.\\n\"\n",
    "    \"Respond with no other explanation but only the content of the prompt that is ready for the model to predict\\n\"\n",
    "    \"Prompt:\"\n",
    ")\n",
    "\n",
    "chat_history.append({'role': 'user', 'content': generate_prompt_request})\n",
    "\n",
    "optimized_prompt_response = chat_with_context(chat_history)\n",
    "chat_history.append({'role': 'assistant', 'content': optimized_prompt_response})\n",
    "print(\"Optimized Prompt:\")\n",
    "print(optimized_prompt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting tweet 1 out of 3817\n",
      "Predicting tweet 1001 out of 3817\n",
      "Predicting tweet 2001 out of 3817\n",
      "Predicting tweet 3001 out of 3817\n",
      "Model Accuracy: 0.6266701598113702\n"
     ]
    }
   ],
   "source": [
    "# Function to predict the label of a given news article\n",
    "def get_prediction(text):\n",
    "    # First part: Get a detailed response following the general guidelines of the prompt\n",
    "    initial_prompt = (\n",
    "        \"Follow the guidelines of the prompt:\\n\"\n",
    "        f\"{optimized_prompt_response}\\n\\n\"\n",
    "        f\"Tweet: {text}\\n\"\n",
    "        \"### Initial Analysis:\\n\"\n",
    "        \"Provide your detailed analysis and suggest a category based on the content of the tweet.\"\n",
    "    )\n",
    "    \n",
    "    initial_response = ollama.generate(model='llama3', prompt=initial_prompt)\n",
    "    detailed_analysis = initial_response['response'].strip()\n",
    "\n",
    "    # Second part: Narrow down to just the predicted label\n",
    "    final_prompt = (\n",
    "        \"Based on the detailed analysis, respond with only the category name:\\n\"\n",
    "        f\"{detailed_analysis}\\n\"\n",
    "        \"### Requirements:\\n\"\n",
    "        \"1. Respond with only a single-digit (0 for not ironic, 1 for ironic).\\n\"\n",
    "        \"2. Do not provide any additional text or explanation.\\n\"\n",
    "        \"Respond with only '0' or '1':\"\n",
    "    )\n",
    "\n",
    "    final_response = ollama.generate(model='llama3', prompt=final_prompt)\n",
    "    prediction = final_response['response'].strip().replace(\"**\", \"\").replace(\"'\", \"\").replace('\"', '')\n",
    "    if '1' in prediction:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "predictions = []\n",
    "for i, text in enumerate(texts):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Predicting tweet {i+1} out of {len(texts)}\")\n",
    "    # if i == 1000:\n",
    "    #     break\n",
    "    prediction = get_prediction(text)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# Step 6: Evaluate Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "predictions = [\"1\" if \"1\" in p else \"0\" for p in predictions]\n",
    "accuracy = accuracy_score(labels[:len(predictions)], predictions)\n",
    "print(f\"Model Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
