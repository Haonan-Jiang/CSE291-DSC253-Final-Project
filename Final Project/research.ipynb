{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49bcd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63229f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                              TITLE  \\\n",
      "0   1        Reconstructing Subject-Specific Effect Maps   \n",
      "1   2                 Rotation Invariance Neural Network   \n",
      "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
      "3   4  A finite element approximation for the stochas...   \n",
      "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
      "\n",
      "                                            ABSTRACT  Computer Science  \\\n",
      "0    Predictive models allow subject-specific inf...                 1   \n",
      "1    Rotation invariance and translation invarian...                 1   \n",
      "2    We introduce and develop the notion of spher...                 0   \n",
      "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
      "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
      "\n",
      "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
      "0        0            0           0                     0   \n",
      "1        0            0           0                     0   \n",
      "2        0            1           0                     0   \n",
      "3        0            1           0                     0   \n",
      "4        0            0           1                     0   \n",
      "\n",
      "   Quantitative Finance  \n",
      "0                     0  \n",
      "1                     0  \n",
      "2                     0  \n",
      "3                     0  \n",
      "4                     0  \n",
      "      ID                                              TITLE  \\\n",
      "0  20973  Closed-form Marginal Likelihood in Gamma-Poiss...   \n",
      "1  20974  Laboratory mid-IR spectra of equilibrated and ...   \n",
      "2  20975         Case For Static AMSDU Aggregation in WLANs   \n",
      "3  20976  The $Gaia$-ESO Survey: the inner disk intermed...   \n",
      "4  20977  Witness-Functions versus Interpretation-Functi...   \n",
      "\n",
      "                                            ABSTRACT  \n",
      "0    We present novel understandings of the Gamma...  \n",
      "1    Meteorites contain minerals from Solar Syste...  \n",
      "2    Frame aggregation is a mechanism by which mu...  \n",
      "3    Milky Way open clusters are very diverse in ...  \n",
      "4    Proving that a cryptographic protocol is cor...  \n"
     ]
    }
   ],
   "source": [
    "data_path = 'dataset/research'\n",
    "train_df = pd.read_csv(data_path + '/train.csv')\n",
    "test_df = pd.read_csv(data_path + '/test.csv')\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b46b6640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Text and Labels Head:\n",
      "                                               TITLE  \\\n",
      "0        Reconstructing Subject-Specific Effect Maps   \n",
      "1                 Rotation Invariance Neural Network   \n",
      "2  Spherical polyharmonics and Poisson kernels fo...   \n",
      "3  A finite element approximation for the stochas...   \n",
      "4  Comparative study of Discrete Wavelet Transfor...   \n",
      "\n",
      "                                            ABSTRACT  \n",
      "0    Predictive models allow subject-specific inf...  \n",
      "1    Rotation invariance and translation invarian...  \n",
      "2    We introduce and develop the notion of spher...  \n",
      "3    The stochastic Landau--Lifshitz--Gilbert (LL...  \n",
      "4    Fourier-transform infra-red (FTIR) spectra o...  \n",
      "   Computer Science  Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
      "0                 1        0            0           0                     0   \n",
      "1                 1        0            0           0                     0   \n",
      "2                 0        0            1           0                     0   \n",
      "3                 0        0            1           0                     0   \n",
      "4                 1        0            0           1                     0   \n",
      "\n",
      "   Quantitative Finance  \n",
      "0                     0  \n",
      "1                     0  \n",
      "2                     0  \n",
      "3                     0  \n",
      "4                     0  \n",
      "\n",
      "Test Text Head:\n",
      "                                               TITLE  \\\n",
      "0  Closed-form Marginal Likelihood in Gamma-Poiss...   \n",
      "1  Laboratory mid-IR spectra of equilibrated and ...   \n",
      "2         Case For Static AMSDU Aggregation in WLANs   \n",
      "3  The $Gaia$-ESO Survey: the inner disk intermed...   \n",
      "4  Witness-Functions versus Interpretation-Functi...   \n",
      "\n",
      "                                            ABSTRACT  \n",
      "0    We present novel understandings of the Gamma...  \n",
      "1    Meteorites contain minerals from Solar Syste...  \n",
      "2    Frame aggregation is a mechanism by which mu...  \n",
      "3    Milky Way open clusters are very diverse in ...  \n",
      "4    Proving that a cryptographic protocol is cor...  \n"
     ]
    }
   ],
   "source": [
    "train_text = train_df[['TITLE', 'ABSTRACT']]\n",
    "train_labels = train_df[['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']]\n",
    "test_text = test_df[['TITLE', 'ABSTRACT']]\n",
    "\n",
    "print(\"Train Text and Labels Head:\")\n",
    "print(train_text.head())\n",
    "print(train_labels.head())\n",
    "\n",
    "print(\"\\nTest Text Head:\")\n",
    "print(test_text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with more than one label:  5044\n"
     ]
    }
   ],
   "source": [
    "# print the number of samples that have more than one label\n",
    "train_labels = train_df[['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']]\n",
    "# when axis=1, it means we are summing the number of labels in each row\n",
    "num_labels = train_labels.sum(axis=1)\n",
    "print(\"Number of samples with more than one label: \", len(num_labels[num_labels > 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f203156",
   "metadata": {},
   "source": [
    "# Basic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23cceb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for sample 1...\n",
      "Predicting for sample 101...\n",
      "Predicting for sample 201...\n",
      "Predicting for sample 301...\n",
      "Predicting for sample 401...\n",
      "Predicting for sample 501...\n",
      "Predicting for sample 601...\n",
      "Predicting for sample 701...\n",
      "Predicting for sample 801...\n",
      "Predicting for sample 901...\n",
      "Predicting for sample 1001...\n",
      "Predicting for sample 1101...\n",
      "Predicting for sample 1201...\n",
      "Predicting for sample 1301...\n",
      "Predicting for sample 1401...\n",
      "Predicting for sample 1501...\n",
      "Predicting for sample 1601...\n",
      "Predicting for sample 1701...\n",
      "Predicting for sample 1801...\n",
      "Predicting for sample 1901...\n",
      "Predicting for sample 2001...\n",
      "Predicting for sample 2101...\n",
      "Predicting for sample 2201...\n",
      "Predicting for sample 2301...\n",
      "Predicting for sample 2401...\n",
      "Predicting for sample 2501...\n",
      "Predicting for sample 2601...\n",
      "Predicting for sample 2701...\n",
      "Predicting for sample 2801...\n",
      "Predicting for sample 2901...\n",
      "Predicting for sample 3001...\n",
      "Predicting for sample 3101...\n",
      "Predicting for sample 3201...\n",
      "Predicting for sample 3301...\n",
      "Predicting for sample 3401...\n",
      "Predicting for sample 3501...\n",
      "Predicting for sample 3601...\n",
      "Predicting for sample 3701...\n",
      "Predicting for sample 3801...\n",
      "Predicting for sample 3901...\n",
      "Predicting for sample 4001...\n",
      "Predicting for sample 4101...\n",
      "Predicting for sample 4201...\n",
      "Predicting for sample 4301...\n",
      "Predicting for sample 4401...\n",
      "Predicting for sample 4501...\n",
      "Predicting for sample 4601...\n",
      "Predicting for sample 4701...\n",
      "Predicting for sample 4801...\n",
      "Predicting for sample 4901...\n",
      "Predicting for sample 5001...\n",
      "Predicting for sample 5101...\n",
      "Predicting for sample 5201...\n",
      "Predicting for sample 5301...\n",
      "Predicting for sample 5401...\n",
      "Predicting for sample 5501...\n",
      "Predicting for sample 5601...\n",
      "Predicting for sample 5701...\n",
      "Predicting for sample 5801...\n",
      "Predicting for sample 5901...\n",
      "Predicting for sample 6001...\n",
      "Predicting for sample 6101...\n",
      "Predicting for sample 6201...\n",
      "Predicting for sample 6301...\n",
      "Predicting for sample 6401...\n",
      "Predicting for sample 6501...\n",
      "Predicting for sample 6601...\n",
      "Predicting for sample 6701...\n",
      "Predicting for sample 6801...\n",
      "Predicting for sample 6901...\n",
      "Predicting for sample 7001...\n",
      "Predicting for sample 7101...\n",
      "Predicting for sample 7201...\n",
      "Predicting for sample 7301...\n",
      "Predicting for sample 7401...\n",
      "Predicting for sample 7501...\n",
      "Predicting for sample 7601...\n",
      "Predicting for sample 7701...\n",
      "Predicting for sample 7801...\n",
      "Predicting for sample 7901...\n",
      "Predicting for sample 8001...\n",
      "Predicting for sample 8101...\n",
      "Predicting for sample 8201...\n",
      "Predicting for sample 8301...\n",
      "Predicting for sample 8401...\n",
      "Predicting for sample 8501...\n",
      "Predicting for sample 8601...\n",
      "Predicting for sample 8701...\n",
      "Predicting for sample 8801...\n",
      "Predicting for sample 8901...\n",
      "Predicting for sample 9001...\n",
      "Predicting for sample 9101...\n",
      "Predicting for sample 9201...\n",
      "Predicting for sample 9301...\n",
      "Predicting for sample 9401...\n",
      "Predicting for sample 9501...\n",
      "Predicting for sample 9601...\n",
      "Predicting for sample 9701...\n",
      "Predicting for sample 9801...\n",
      "Predicting for sample 9901...\n",
      "Predicting for sample 10001...\n",
      "Predicting for sample 10101...\n",
      "Predicting for sample 10201...\n",
      "Predicting for sample 10301...\n",
      "Predicting for sample 10401...\n",
      "Predicting for sample 10501...\n",
      "Predicting for sample 10601...\n",
      "Predicting for sample 10701...\n",
      "Predicting for sample 10801...\n",
      "Predicting for sample 10901...\n",
      "Predicting for sample 11001...\n",
      "Predicting for sample 11101...\n",
      "Predicting for sample 11201...\n",
      "Predicting for sample 11301...\n",
      "Predicting for sample 11401...\n",
      "Predicting for sample 11501...\n",
      "Predicting for sample 11601...\n",
      "Predicting for sample 11701...\n",
      "Predicting for sample 11801...\n",
      "Predicting for sample 11901...\n",
      "Predicting for sample 12001...\n",
      "Predicting for sample 12101...\n",
      "Predicting for sample 12201...\n",
      "Predicting for sample 12301...\n",
      "Predicting for sample 12401...\n",
      "Predicting for sample 12501...\n",
      "Predicting for sample 12601...\n",
      "Predicting for sample 12701...\n",
      "Predicting for sample 12801...\n",
      "Predicting for sample 12901...\n",
      "Predicting for sample 13001...\n",
      "Predicting for sample 13101...\n",
      "Predicting for sample 13201...\n",
      "Predicting for sample 13301...\n",
      "Predicting for sample 13401...\n",
      "Predicting for sample 13501...\n",
      "Predicting for sample 13601...\n",
      "Predicting for sample 13701...\n",
      "Predicting for sample 13801...\n",
      "Predicting for sample 13901...\n",
      "Predicting for sample 14001...\n",
      "Predicting for sample 14101...\n",
      "Predicting for sample 14201...\n",
      "Predicting for sample 14301...\n",
      "Predicting for sample 14401...\n",
      "Predicting for sample 14501...\n",
      "Predicting for sample 14601...\n",
      "Predicting for sample 14701...\n",
      "Predicting for sample 14801...\n",
      "Predicting for sample 14901...\n",
      "Predicting for sample 15001...\n",
      "Predicting for sample 15101...\n",
      "Predicting for sample 15201...\n",
      "Predicting for sample 15301...\n",
      "Predicting for sample 15401...\n",
      "Predicting for sample 15501...\n",
      "Predicting for sample 15601...\n",
      "Predicting for sample 15701...\n",
      "Predicting for sample 15801...\n",
      "Predicting for sample 15901...\n",
      "Predicting for sample 16001...\n",
      "Predicting for sample 16101...\n",
      "Predicting for sample 16201...\n",
      "Predicting for sample 16301...\n",
      "Predicting for sample 16401...\n",
      "Predicting for sample 16501...\n",
      "Predicting for sample 16601...\n",
      "Predicting for sample 16701...\n",
      "Predicting for sample 16801...\n",
      "Predicting for sample 16901...\n",
      "Predicting for sample 17001...\n",
      "Predicting for sample 17101...\n",
      "Predicting for sample 17201...\n",
      "Predicting for sample 17301...\n",
      "Predicting for sample 17401...\n",
      "Predicting for sample 17501...\n",
      "Predicting for sample 17601...\n",
      "Predicting for sample 17701...\n",
      "Predicting for sample 17801...\n",
      "Predicting for sample 17901...\n",
      "Predicting for sample 18001...\n",
      "Predicting for sample 18101...\n",
      "Predicting for sample 18201...\n",
      "Predicting for sample 18301...\n",
      "Predicting for sample 18401...\n",
      "Predicting for sample 18501...\n",
      "Predicting for sample 18601...\n",
      "Predicting for sample 18701...\n",
      "Predicting for sample 18801...\n",
      "Predicting for sample 18901...\n",
      "Predicting for sample 19001...\n",
      "Predicting for sample 19101...\n",
      "Predicting for sample 19201...\n",
      "Predicting for sample 19301...\n",
      "Predicting for sample 19401...\n",
      "Predicting for sample 19501...\n",
      "Predicting for sample 19601...\n",
      "Predicting for sample 19701...\n",
      "Predicting for sample 19801...\n",
      "Predicting for sample 19901...\n",
      "Predicting for sample 20001...\n",
      "Predicting for sample 20101...\n",
      "Predicting for sample 20201...\n",
      "Predicting for sample 20301...\n",
      "Predicting for sample 20401...\n",
      "Predicting for sample 20501...\n",
      "Predicting for sample 20601...\n",
      "Predicting for sample 20701...\n",
      "Predicting for sample 20801...\n",
      "Predicting for sample 20901...\n",
      "Test Sample 1:\n",
      "Title: Closed-form Marginal Likelihood in Gamma-Poisson Matrix Factorization\n",
      "Abstract:   We present novel understandings of the Gamma-Poisson (GaP) model, a\n",
      "probabilistic matrix factorization model for count data. We show that GaP can\n",
      "be rewritten free of the score/activation matrix. This gives us new insights\n",
      "about the estimation of the topic/dictionary matrix by maximum marginal\n",
      "likelihood estimation. In particular, this explains the robustness of this\n",
      "estimator to over-specified values of the factorization rank, especially its\n",
      "ability to automatically prune irrelevant dictionary columns, as empirically\n",
      "observed in previous work. The marginalization of the activation matrix leads\n",
      "in turn to a new Monte Carlo Expectation-Maximization algorithm with favorable\n",
      "properties.\n",
      "\n",
      "Predicted Category: Statistics\n",
      "\n",
      "Actual Category: Computer Science\n",
      "\n",
      "Test Sample 2:\n",
      "Title: Laboratory mid-IR spectra of equilibrated and igneous meteorites. Searching for observables of planetesimal debris\n",
      "Abstract:   Meteorites contain minerals from Solar System asteroids with different\n",
      "properties (like size, presence of water, core formation). We provide new\n",
      "mid-IR transmission spectra of powdered meteorites to obtain templates of how\n",
      "mid-IR spectra of asteroidal debris would look like. This is essential for\n",
      "interpreting mid-IR spectra of past and future space observatories, like the\n",
      "James Webb Space Telescope. We show that the transmission spectra of wet and\n",
      "dry chondrites, carbonaceous and ordinary chondrites and achondrite and\n",
      "chondrite meteorites are distinctly different in a way one can distinguish in\n",
      "astronomical mid-IR spectra. The two observables that spectroscopically\n",
      "separate the different meteorites groups (and thus the different types of\n",
      "parent bodies) are the pyroxene-olivine feature strength ratio and the peak\n",
      "shift of the olivine spectral features due to an increase in the iron\n",
      "concentration of the olivine.\n",
      "\n",
      "Predicted Category: Computer Science\n",
      "\n",
      "Actual Category: Computer Science\n",
      "\n",
      "Test Sample 3:\n",
      "Title: Case For Static AMSDU Aggregation in WLANs\n",
      "Abstract:   Frame aggregation is a mechanism by which multiple frames are combined into a\n",
      "single transmission unit over the air. Frames aggregated at the AMSDU level use\n",
      "a common CRC check to enforce integrity. For longer aggregated AMSDU frames,\n",
      "the packet error rate increases significantly for the same bit error rate.\n",
      "Hence, multiple studies have proposed doing AMSDU aggregation adaptively based\n",
      "on the error rate. This study evaluates if there is a \\emph{practical}\n",
      "advantage in doing adaptive AMSDU aggregation based on the link bit error rate.\n",
      "Evaluations on a model show that instead of implementing a complex adaptive\n",
      "AMSDU frame aggregation mechanism which impact queuing and other implementation\n",
      "aspects, it is easier to influence packet error rate with traditional\n",
      "mechanisms while keeping the AMSDU aggregation logic simple.\n",
      "\n",
      "Predicted Category: Mathematics\n",
      "\n",
      "Actual Category: Mathematics\n",
      "\n",
      "Test Sample 4:\n",
      "Title: The $Gaia$-ESO Survey: the inner disk intermediate-age open cluster NGC 6802\n",
      "Abstract:   Milky Way open clusters are very diverse in terms of age, chemical\n",
      "composition, and kinematic properties. Intermediate-age and old open clusters\n",
      "are less common, and it is even harder to find them inside the solar\n",
      "Galactocentric radius, due to the high mortality rate and strong extinction\n",
      "inside this region. NGC 6802 is one of the inner disk open clusters (IOCs)\n",
      "observed by the $Gaia$-ESO survey (GES). This cluster is an important target\n",
      "for calibrating the abundances derived in the survey due to the kinematic and\n",
      "chemical homogeneity of the members in open clusters. Using the measurements\n",
      "from $Gaia$-ESO internal data release 4 (iDR4), we identify 95 main-sequence\n",
      "dwarfs as cluster members from the GIRAFFE target list, and eight giants as\n",
      "cluster members from the UVES target list. The dwarf cluster members have a\n",
      "median radial velocity of $13.6\\pm1.9$ km s$^{-1}$, while the giant cluster\n",
      "members have a median radial velocity of $12.0\\pm0.9$ km s$^{-1}$ and a median\n",
      "[Fe/H] of $0.10\\pm0.02$ dex. The color-magnitude diagram of these cluster\n",
      "members suggests an age of $0.9\\pm0.1$ Gyr, with $(m-M)_0=11.4$ and\n",
      "$E(B-V)=0.86$. We perform the first detailed chemical abundance analysis of NGC\n",
      "6802, including 27 elemental species. To gain a more general picture about\n",
      "IOCs, the measurements of NGC 6802 are compared with those of other IOCs\n",
      "previously studied by GES, that is, NGC 4815, Trumpler 20, NGC 6705, and\n",
      "Berkeley 81. NGC 6802 shows similar C, N, Na, and Al abundances as other IOCs.\n",
      "These elements are compared with nucleosynthetic models as a function of\n",
      "cluster turn-off mass. The $\\alpha$, iron-peak, and neutron-capture elements\n",
      "are also explored in a self-consistent way.\n",
      "\n",
      "Predicted Category: Mathematics\n",
      "\n",
      "Actual Category: Mathematics\n",
      "\n",
      "Test Sample 5:\n",
      "Title: Witness-Functions versus Interpretation-Functions for Secrecy in Cryptographic Protocols: What to Choose?\n",
      "Abstract:   Proving that a cryptographic protocol is correct for secrecy is a hard task.\n",
      "One of the strongest strategies to reach this goal is to show that it is\n",
      "increasing, which means that the security level of every single atomic message\n",
      "exchanged in the protocol, safely evaluated, never deceases. Recently, two\n",
      "families of functions have been proposed to measure the security level of\n",
      "atomic messages. The first one is the family of interpretation-functions. The\n",
      "second is the family of witness-functions. In this paper, we show that the\n",
      "witness-functions are more efficient than interpretation-functions. We give a\n",
      "detailed analysis of an ad-hoc protocol on which the witness-functions succeed\n",
      "in proving its correctness for secrecy while the interpretation-functions fail\n",
      "to do so.\n",
      "\n",
      "Predicted Category: Computer Science\n",
      "\n",
      "Actual Category: Computer Science\n",
      "\n",
      "Accuracy: 0.23598130841121495\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ollama\n",
    "\n",
    "# Load the data\n",
    "data_path = 'dataset/research'\n",
    "train_df = pd.read_csv(data_path + '/train.csv')\n",
    "test_df = pd.read_csv(data_path + '/test.csv')\n",
    "\n",
    "# print(train_df.head())\n",
    "# print(test_df.head())\n",
    "\n",
    "train_text = train_df[['TITLE', 'ABSTRACT']]\n",
    "train_labels = train_df[['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']]\n",
    "test_text = test_df[['TITLE', 'ABSTRACT']]\n",
    "\n",
    "labels = []\n",
    "for index, row in train_labels.iterrows():\n",
    "    for i, label in enumerate(row):\n",
    "        if label == 1:\n",
    "            labels.append(train_labels.columns[i])\n",
    "\n",
    "# Function to interact with the Ollama API\n",
    "def get_prediction(title, abstract):\n",
    "    response = ollama.chat(model='llama3', messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': f\"Title: {title}\\nAbstract: {abstract}\\nPredict the category from one of the followings categories: [Computer Science, Physics, Mathematics, Statistics, Quantitative Biology, Quantitative Finance]. Only respond with the category name.\",\n",
    "        },\n",
    "    ])\n",
    "    return response['message']['content']\n",
    "\n",
    "# Predict for the test set\n",
    "test_predictions = []\n",
    "for index, row in train_text.iterrows():\n",
    "    if index % 100 == 0:\n",
    "        print(f\"Predicting for sample {index+1}...\")\n",
    "    # if index == 1000:\n",
    "    #     break\n",
    "    prediction = get_prediction(row['TITLE'], row['ABSTRACT'])\n",
    "    test_predictions.append(prediction)\n",
    "\n",
    "# Display some predictions\n",
    "for i, prediction in enumerate(test_predictions[:5]):\n",
    "    print(f\"Test Sample {i+1}:\")\n",
    "    print(f\"Title: {test_text.iloc[i]['TITLE']}\")\n",
    "    print(f\"Abstract: {test_text.iloc[i]['ABSTRACT']}\")\n",
    "    print(f\"Predicted Category: {prediction}\\n\")\n",
    "    print(f\"Actual Category: {labels[i]}\\n\")\\\n",
    "    \n",
    "# calculate the accuracy\n",
    "correct = 0\n",
    "for i, prediction in enumerate(test_predictions):\n",
    "    if prediction == labels[i]:\n",
    "        correct += 1\n",
    "accuracy = correct / len(test_predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8edb5313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Samples:\n",
      "Here are some sample research paper titles and abstracts, along with their intended categories:\n",
      "\n",
      "**Samples that should be easily classified:**\n",
      "\n",
      "1. **Computer Science:** \"Efficient Algorithm for Solving Traveling Salesman Problems using Genetic Programming\"\n",
      "\t* Abstract: This paper proposes a novel algorithm for solving the classic traveling salesman problem using genetic programming. The proposed approach is compared to existing methods and shows improved performance.\n",
      "2. **Physics:** \"Measurement of Quantum Entanglement in Superconducting Circuits\"\n",
      "\t* Abstract: In this study, we investigate the measurement of quantum entanglement in superconducting circuits. Our results demonstrate a significant improvement in entanglement measurement precision using a novel technique.\n",
      "3. **Mathematics:** \"New Proof of the Four-Color Theorem using Topological Methods\"\n",
      "\t* Abstract: This paper presents a new proof of the four-color theorem using topological methods. We show that our approach is more efficient and easier to understand than previous proofs.\n",
      "\n",
      "**Samples that might be confusing:**\n",
      "\n",
      "1. **Quantitative Biology:** \"Machine Learning Approaches for Predicting Protein Structure from Sequence Data\"\n",
      "\t* Abstract: This study applies machine learning techniques to predict protein structure from sequence data. Our results show promising improvements in accuracy compared to traditional methods.\n",
      "2. **Statistics:** \"Bayesian Inference for High-Dimensional Data using Variational Methods\"\n",
      "\t* Abstract: In this paper, we develop a Bayesian inference framework for high-dimensional data using variational methods. Our approach is shown to be efficient and effective for large-scale datasets.\n",
      "3. **Quantitative Finance:** \"Risk-Neutral Valuation of American Options using Stochastic Processes\"\n",
      "\t* Abstract: This study develops a risk-neutral valuation framework for American options using stochastic processes. Our results demonstrate improved accuracy compared to existing methods.\n",
      "\n",
      "**Samples that might be misclassified:**\n",
      "\n",
      "1. **Mathematics/Computer Science:** \"Design and Analysis of a Distributed Algorithm for Solving Partial Differential Equations\"\n",
      "\t* Abstract: In this paper, we design and analyze a distributed algorithm for solving partial differential equations on parallel architectures. Our approach is shown to be efficient and scalable.\n",
      "2. **Physics/Mathematics:** \"Geometric Analysis of Gravitational Waves using Numerical Methods\"\n",
      "\t* Abstract: This study performs a geometric analysis of gravitational waves using numerical methods. We demonstrate improved understanding of the waveforms and potential applications in astrophysics.\n",
      "\n",
      "Please note that these samples are not meant to be exhaustive or representative of all possible research papers, but rather serve as examples to help train a machine learning model for categorizing research papers.\n",
      "Analysis of Samples:\n",
      "**Identifying features and patterns:**\n",
      "\n",
      "1. **Computer Science:** Keywords like \"algorithm\", \"genetic programming\", \"parallel architectures\" suggest a focus on computational methods.\n",
      "2. **Physics:** Terms like \"quantum entanglement\", \"superconducting circuits\", \"gravitational waves\" indicate a study of fundamental physical phenomena.\n",
      "3. **Mathematics:** Phrases such as \"new proof\", \"topological methods\", \"Four-Color Theorem\" suggest a focus on mathematical theories and proofs.\n",
      "4. **Quantitative Biology:** Keywords like \"protein structure\", \"sequence data\", \"machine learning\" imply a study of biological systems using computational methods.\n",
      "5. **Statistics:** Terms like \"Bayesian inference\", \"variational methods\", \"high-dimensional data\" suggest an analysis of statistical models and their applications.\n",
      "6. **Quantitative Finance:** Phrases such as \"risk-neutral valuation\", \"American options\", \"stochastic processes\" indicate a study of financial modeling and risk management.\n",
      "\n",
      "**Pitfalls and sources of confusion:**\n",
      "\n",
      "1. **Blurred boundaries:** Papers that combine methods from multiple fields (e.g., physics and computer science) can be challenging to categorize.\n",
      "2. **Domain-specific terminology:** Jargon specific to each field can make it difficult for the model to distinguish between categories.\n",
      "3. **Abstract complexity:** Papers with complex abstracts or those that focus on methodology rather than specific findings might be harder to classify.\n",
      "4. **Category overlap:** Categories like \"Physics/Mathematics\" and \"Computer Science/Statistics\" may require additional features or fine-tuning to accurately categorize papers.\n",
      "\n",
      "To mitigate these challenges, it's essential to:\n",
      "\n",
      "1. Use a diverse set of training samples that cover various topics and styles.\n",
      "2. Employ natural language processing (NLP) techniques to extract relevant keywords and phrases from the abstracts.\n",
      "3. Consider incorporating domain-specific ontologies or taxonomies to help the model understand the relationships between categories.\n",
      "\n",
      "By being aware of these potential pitfalls and taking steps to address them, we can improve the accuracy and reliability of our research paper categorization model.\n",
      "Criteria for Identification:\n",
      "Based on the analysis, here are some guidelines for accurately classifying samples into specific labels:\n",
      "\n",
      "**Computer Science:**\n",
      "\n",
      "* Focus on keywords like \"algorithm\", \"genetic programming\", and \"parallel architectures\".\n",
      "* Look for phrases indicating computational methods, such as \"simulation\", \"optimization\", or \"machine learning\".\n",
      "* Pay attention to the presence of technical terms related to computer science, such as \"data structures\", \"compilers\", or \"operating systems\".\n",
      "\n",
      "**Physics:**\n",
      "\n",
      "* Identify terms like \"quantum entanglement\", \"superconducting circuits\", and \"gravitational waves\".\n",
      "* Watch for phrases indicating experimental methods, such as \"experimental setup\", \"measurement techniques\", or \"instrumentation\".\n",
      "* Be aware of the presence of technical terms related to physics, such as \"particles\", \"fields\", or \"symmetries\".\n",
      "\n",
      "**Mathematics:**\n",
      "\n",
      "* Focus on phrases like \"new proof\", \"topological methods\", and \"Four-Color Theorem\".\n",
      "* Look for keywords indicating mathematical structures, such as \"algebraic geometry\", \"differential equations\", or \"number theory\".\n",
      "* Pay attention to the presence of technical terms related to mathematics, such as \"groups\", \"modules\", or \"categories\".\n",
      "\n",
      "**Quantitative Biology:**\n",
      "\n",
      "* Identify keywords like \"protein structure\", \"sequence data\", and \"machine learning\".\n",
      "* Watch for phrases indicating biological systems, such as \"cellular processes\", \"genetic regulation\", or \"biological networks\".\n",
      "* Be aware of the presence of technical terms related to biology, such as \"molecular biology\", \"biochemistry\", or \"ecology\".\n",
      "\n",
      "**Statistics:**\n",
      "\n",
      "* Focus on keywords like \"Bayesian inference\", \"variational methods\", and \"high-dimensional data\".\n",
      "* Look for phrases indicating statistical analysis, such as \"hypothesis testing\", \"confidence intervals\", or \"regression models\".\n",
      "* Pay attention to the presence of technical terms related to statistics, such as \"probability theory\", \"stochastic processes\", or \"statistical inference\".\n",
      "\n",
      "**Quantitative Finance:**\n",
      "\n",
      "* Identify keywords like \"risk-neutral valuation\", \"American options\", and \"stochastic processes\".\n",
      "* Watch for phrases indicating financial modeling, such as \"portfolio optimization\", \"risk management\", or \"financial derivatives\".\n",
      "* Be aware of the presence of technical terms related to finance, such as \"economics\", \"accounting\", or \"financial markets\".\n",
      "\n",
      "By focusing on these features and cues, the model can improve its accuracy in classifying samples into specific labels.\n",
      "Optimized Prompt:\n",
      "Here is the optimized prompt:\n",
      "\n",
      "\"Classify this research paper as one of the following types: Computer Science, Physics, Mathematics, Quantitative Biology, Statistics, or Quantitative Finance. Consider keywords such as algorithm, genetic programming, parallel architectures, quantum entanglement, superconducting circuits, gravitational waves, new proof, topological methods, Four-Color Theorem, protein structure, sequence data, machine learning, Bayesian inference, variational methods, high-dimensional data, risk-neutral valuation, American options, stochastic processes. Additionally, look for phrases indicating computational methods, experimental methods, mathematical structures, biological systems, statistical analysis, and financial modeling.\"\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# Function to interact with the Ollama API\n",
    "def chat_with_context(history):\n",
    "    response = ollama.chat(model='llama3', messages=history)\n",
    "    return response['message']['content']\n",
    "\n",
    "# Initialize the chat history\n",
    "chat_history = []\n",
    "\n",
    "# Step 1: Add Initial Task Description\n",
    "task_description = \"We need to predict the research paper type into one of the following categories: (Computer Science, Physics, Mathematics, Statistics, Quantitative Biology, and Quantitative Finance) based on its title and abstract. Think step-by-step through how you would approach this task\"\n",
    "chat_history.append({\n",
    "    'role': 'user',\n",
    "    'content': task_description\n",
    "})\n",
    "\n",
    "# Step 2: Generate Samples\n",
    "generate_samples_request = \"Please generate a few samples that are likely to be identified as a certain label and a few samples that are likely to confuse the model into making wrong predictions.\"\n",
    "chat_history.append({\n",
    "    'role': 'user',\n",
    "    'content': generate_samples_request\n",
    "})\n",
    "\n",
    "samples_response = chat_with_context(chat_history)\n",
    "chat_history.append({\n",
    "    'role': 'assistant',\n",
    "    'content': samples_response\n",
    "})\n",
    "print(\"Generated Samples:\")\n",
    "print(samples_response)\n",
    "\n",
    "# Step 3: Analyze Samples\n",
    "analyze_samples_request = f\"Here are some samples: {samples_response}\\n  What keywords, phrases, or patterns distinguish each label? What pitfalls or sources of confusion did you encounter? \"\n",
    "chat_history.append({\n",
    "    'role': 'user',\n",
    "    'content': analyze_samples_request\n",
    "})\n",
    "\n",
    "analysis_response = chat_with_context(chat_history)\n",
    "chat_history.append({\n",
    "    'role': 'assistant',\n",
    "    'content': analysis_response\n",
    "})\n",
    "print(\"Analysis of Samples:\")\n",
    "print(analysis_response)\n",
    "\n",
    "# Step 4: Identify Criteria\n",
    "identify_criteria_request = f\"Based on the following analysis: {analysis_response}\\n provide guidelines for accurately classifying sample into specific label. What features or cues should the model focus on?\"\n",
    "chat_history.append({\n",
    "    'role': 'user',\n",
    "    'content': identify_criteria_request\n",
    "})\n",
    "\n",
    "criteria_response = chat_with_context(chat_history)\n",
    "chat_history.append({\n",
    "    'role': 'assistant',\n",
    "    'content': criteria_response\n",
    "})\n",
    "print(\"Criteria for Identification:\")\n",
    "print(criteria_response)\n",
    "\n",
    "# Step 5: Generate Optimized Prompt\n",
    "generate_prompt_request = f\"Based on the following criteria: {criteria_response}\\n Generate an optimized prompt for the model to predict the research paper type. Make sure the prompt highlights essential features and minimizes potential sources of confusion. Respond with only the content of optimized prompt.\"\n",
    "chat_history.append({\n",
    "    'role': 'user',\n",
    "    'content': generate_prompt_request\n",
    "})\n",
    "\n",
    "optimized_prompt_response = chat_with_context(chat_history)\n",
    "chat_history.append({\n",
    "    'role': 'assistant',\n",
    "    'content': optimized_prompt_response\n",
    "})\n",
    "print(\"Optimized Prompt:\")\n",
    "print(optimized_prompt_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Samples:\n",
      "Let's say we have a research paper with the following title and abstract:\n",
      "\n",
      "**Title:** \"Efficient Computation of Optimal Trading Strategies using Deep Reinforcement Learning\"\n",
      "\n",
      "**Abstract:** \"We propose a novel approach to computing optimal trading strategies by combining deep reinforcement learning techniques with Monte Carlo methods. Our method leverages the power of neural networks to learn complex market dynamics, while also incorporating risk management constraints. We demonstrate the effectiveness of our approach through simulations and experiments on real-world financial data.\"\n",
      "\n",
      "Here's my thought process to classify this paper:\n",
      "\n",
      "**Step 1: Initial Impression**\n",
      "The title immediately catches my attention with its mention of \"deep reinforcement learning\" and \"optimal trading strategies\". I get a sense that this paper might be related to computer science, possibly even machine learning or artificial intelligence.\n",
      "\n",
      "**Step 2: Key Terms Extraction**\n",
      "I extract the following key terms from the title and abstract:\n",
      "\n",
      "* \"Deep Reinforcement Learning\"\n",
      "* \"Optimal Trading Strategies\"\n",
      "* \"Monte Carlo methods\"\n",
      "* \"Neural Networks\"\n",
      "* \"Risk Management\"\n",
      "\n",
      "These terms seem to be related to computer science, specifically machine learning and artificial intelligence.\n",
      "\n",
      "**Step 3: Conceptual Analysis**\n",
      "I analyze the concepts mentioned in the paper:\n",
      "\n",
      "* \"Trading Strategies\" suggests a connection to finance or economics.\n",
      "* \"Market Dynamics\" implies an understanding of statistical patterns and trends.\n",
      "* \"Risk Management\" is a crucial aspect in finance and decision-making under uncertainty.\n",
      "\n",
      "The combination of machine learning techniques, Monte Carlo methods, and financial concepts hints at a connection to quantitative finance or computational finance.\n",
      "\n",
      "**Step 4: Pattern Identification**\n",
      "I identify patterns that might help me determine the paper's field:\n",
      "\n",
      "* The use of \"deep\" in the title suggests a strong link to computer science, particularly artificial intelligence.\n",
      "* The presence of \"optimal trading strategies\" and \"risk management\" implies a focus on financial decision-making.\n",
      "* The mention of \"Monte Carlo methods\" is a common technique used in computational finance and statistics.\n",
      "\n",
      "**Step 5: Field Classification**\n",
      "Based on my analysis, I would classify this paper into the field of **Quantitative Finance**, specifically within the subfield of **Computational Finance**. The combination of machine learning techniques, Monte Carlo methods, and financial concepts suggests that this paper is focused on developing computational models for financial decision-making.\n",
      "\n",
      "Of course, this thought process can be applied to any research paper, and the field classification may change based on the specific details provided in the title and abstract.\n",
      "Analysis of Samples:\n",
      "**Reflection**\n",
      "\n",
      "Upon reflecting on my thought process, I identified several key decisions and features that led me to classify the paper into the field of Quantitative Finance:\n",
      "\n",
      "1. **Initial Impression**: The title's mention of \"deep reinforcement learning\" and \"optimal trading strategies\" immediately suggested a connection to computer science or artificial intelligence.\n",
      "2. **Key Terms Extraction**: Identifying relevant terms like \"Monte Carlo methods\", \"Neural Networks\", and \"Risk Management\" helped me understand the paper's focus on machine learning, finance, and decision-making under uncertainty.\n",
      "3. **Conceptual Analysis**: Analyzing the concepts mentioned in the paper revealed connections to finance (trading strategies) and statistical patterns (market dynamics).\n",
      "4. **Pattern Identification**: Noting the combination of machine learning techniques, Monte Carlo methods, and financial concepts led me to suspect a focus on computational finance.\n",
      "\n",
      "These features and decisions guided me towards classifying the paper into Quantitative Finance. Here are some guidelines for accurately classifying research papers:\n",
      "\n",
      "**Guidelines**\n",
      "\n",
      "1. **Start with a general understanding**: Begin by reading the title and abstract to get a sense of the paper's main themes.\n",
      "2. **Identify key terms and concepts**: Extract relevant keywords, phrases, and ideas from the title, abstract, and introduction.\n",
      "3. **Analyze conceptual connections**: Examine how these key terms and concepts relate to each other and to broader research fields.\n",
      "4. **Look for patterns and trends**: Identify patterns, such as the combination of machine learning and finance, that may indicate a specific field or subfield.\n",
      "5. **Consider the paper's focus and methodology**: Analyze the paper's objectives, methods, and results to determine whether it is focused on computational modeling, statistical analysis, experimental design, or theoretical development.\n",
      "6. **Consult relevant labels and categories**: Draw from existing classification systems (e.g., ACM Computing Classification System, Journal of Physics: Conference Series) to inform your classification.\n",
      "7. **Be cautious with ambiguous titles**: Some papers may have misleading or unclear titles, so be prepared to re-evaluate the paper's content and concepts if necessary.\n",
      "8. **Use a combination of features**: Don't rely solely on one aspect; consider multiple factors (e.g., title, abstract, introduction, methodology) when making your classification decision.\n",
      "\n",
      "By following these guidelines and reflecting on my thought process, you can develop a systematic approach to accurately classifying research papers into their respective fields.\n",
      "Optimized Prompt:\n",
      "**Optimized Prompt**\n",
      "\n",
      "\"Classify this research paper into its respective field by analyzing the title, abstract, introduction, and methodology. Identify key terms and concepts that reveal connections to specific disciplines or subfields. Consider the following features:\n",
      "\n",
      "* Technical keywords (e.g., algorithms, machine learning, data structures)\n",
      "* Computational methods or tools used (e.g., Monte Carlo, neural networks)\n",
      "* Relevant domains or applications (e.g., finance, biology, physics)\n",
      "* Theoretical frameworks or concepts applied\n",
      "* Experimental designs or data analysis approaches\n",
      "\n",
      "When classifying, consider the following labels:\n",
      "\n",
      "* Computer Science\n",
      "* Physics\n",
      "* Mathematics\n",
      "* Statistics\n",
      "* Quantitative Biology\n",
      "* Quantitative Finance\n",
      "\n",
      "Please provide a concise description of your classification decision and the label(s) you assign to this research paper.\"\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "# Function to interact with the Ollama API\n",
    "def chat_with_context(history):\n",
    "    response = ollama.chat(model='llama3', messages=history)\n",
    "    return response['message']['content']\n",
    "\n",
    "# Initialize the chat history\n",
    "chat_history = []\n",
    "\n",
    "# Step 1: Add Initial Task Description\n",
    "task_description = \"Classify research papers into their respective fields (Computer Science, Physics, Mathematics, Statistics, Quantitative Biology, Quantitative Finance) based on their titles and abstracts. Describe the task and relevant labels.\"\n",
    "chat_history.append({\n",
    "    'role': 'user',\n",
    "    'content': task_description\n",
    "})\n",
    "\n",
    "# Step 2: Generate Samples\n",
    "generate_samples_request = \"Generate a series of thoughts to classify a research paper into its field. Start with the title and abstract, then identify key terms, concepts, and patterns, and finally, determine the paper's field. Show your thought process:\"\n",
    "chat_history.append({\n",
    "    'role': 'user',\n",
    "    'content': generate_samples_request\n",
    "})\n",
    "\n",
    "samples_response = chat_with_context(chat_history)\n",
    "chat_history.append({\n",
    "    'role': 'assistant',\n",
    "    'content': samples_response\n",
    "})\n",
    "print(\"Generated Samples:\")\n",
    "print(samples_response)\n",
    "\n",
    "# Step 3: Analyze Samples\n",
    "analyze_samples_request = f\"Reflect on your thought process. What were the key decisions and features that led you to classify the paper into its field? Provide guidelines for accurately classifying research papers...\"\n",
    "chat_history.append({\n",
    "    'role': 'user',\n",
    "    'content': analyze_samples_request\n",
    "})\n",
    "\n",
    "analysis_response = chat_with_context(chat_history)\n",
    "chat_history.append({\n",
    "    'role': 'assistant',\n",
    "    'content': analysis_response\n",
    "})\n",
    "print(\"Analysis of Samples:\")\n",
    "print(analysis_response)\n",
    "\n",
    "# # Step 4: Identify Criteria\n",
    "# identify_criteria_request = f\"Based on the following analysis: {analysis_response}\\n provide guidelines for accurately classifying sample into specific label. What features or cues should the model focus on?\"\n",
    "# chat_history.append({\n",
    "#     'role': 'user',\n",
    "#     'content': identify_criteria_request\n",
    "# })\n",
    "\n",
    "# criteria_response = chat_with_context(chat_history)\n",
    "# chat_history.append({\n",
    "#     'role': 'assistant',\n",
    "#     'content': criteria_response\n",
    "# })\n",
    "# print(\"Criteria for Identification:\")\n",
    "# print(criteria_response)\n",
    "\n",
    "# Step 5: Generate Optimized Prompt\n",
    "generate_prompt_request = f\"Use your reflected thought process to generate an optimized prompt for classifying research papers into their fields. Make sure the prompt highlights essential features and minimizes potential sources of confusion. Output only the content of the optimized prompt.\"\n",
    "chat_history.append({\n",
    "    'role': 'user',\n",
    "    'content': generate_prompt_request\n",
    "})\n",
    "\n",
    "optimized_prompt_response = chat_with_context(chat_history)\n",
    "chat_history.append({\n",
    "    'role': 'assistant',\n",
    "    'content': optimized_prompt_response\n",
    "})\n",
    "print(\"Optimized Prompt:\")\n",
    "print(optimized_prompt_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c3025dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for sample 1...\n",
      "Predicting for sample 101...\n",
      "Predicting for sample 201...\n",
      "Predicting for sample 301...\n",
      "Predicting for sample 401...\n",
      "Predicting for sample 501...\n",
      "Predicting for sample 601...\n",
      "Predicting for sample 701...\n",
      "Predicting for sample 801...\n",
      "Predicting for sample 901...\n",
      "Predicting for sample 1001...\n",
      "Test Sample 1:\n",
      "Title: Closed-form Marginal Likelihood in Gamma-Poisson Matrix Factorization\n",
      "Abstract:   We present novel understandings of the Gamma-Poisson (GaP) model, a\n",
      "probabilistic matrix factorization model for count data. We show that GaP can\n",
      "be rewritten free of the score/activation matrix. This gives us new insights\n",
      "about the estimation of the topic/dictionary matrix by maximum marginal\n",
      "likelihood estimation. In particular, this explains the robustness of this\n",
      "estimator to over-specified values of the factorization rank, especially its\n",
      "ability to automatically prune irrelevant dictionary columns, as empirically\n",
      "observed in previous work. The marginalization of the activation matrix leads\n",
      "in turn to a new Monte Carlo Expectation-Maximization algorithm with favorable\n",
      "properties.\n",
      "\n",
      "Predicted Category: Computer Science\n",
      "\n",
      "Actual Category: Computer Science\n",
      "\n",
      "Test Sample 2:\n",
      "Title: Laboratory mid-IR spectra of equilibrated and igneous meteorites. Searching for observables of planetesimal debris\n",
      "Abstract:   Meteorites contain minerals from Solar System asteroids with different\n",
      "properties (like size, presence of water, core formation). We provide new\n",
      "mid-IR transmission spectra of powdered meteorites to obtain templates of how\n",
      "mid-IR spectra of asteroidal debris would look like. This is essential for\n",
      "interpreting mid-IR spectra of past and future space observatories, like the\n",
      "James Webb Space Telescope. We show that the transmission spectra of wet and\n",
      "dry chondrites, carbonaceous and ordinary chondrites and achondrite and\n",
      "chondrite meteorites are distinctly different in a way one can distinguish in\n",
      "astronomical mid-IR spectra. The two observables that spectroscopically\n",
      "separate the different meteorites groups (and thus the different types of\n",
      "parent bodies) are the pyroxene-olivine feature strength ratio and the peak\n",
      "shift of the olivine spectral features due to an increase in the iron\n",
      "concentration of the olivine.\n",
      "\n",
      "Predicted Category: Computer Science\n",
      "\n",
      "Actual Category: Computer Science\n",
      "\n",
      "Test Sample 3:\n",
      "Title: Case For Static AMSDU Aggregation in WLANs\n",
      "Abstract:   Frame aggregation is a mechanism by which multiple frames are combined into a\n",
      "single transmission unit over the air. Frames aggregated at the AMSDU level use\n",
      "a common CRC check to enforce integrity. For longer aggregated AMSDU frames,\n",
      "the packet error rate increases significantly for the same bit error rate.\n",
      "Hence, multiple studies have proposed doing AMSDU aggregation adaptively based\n",
      "on the error rate. This study evaluates if there is a \\emph{practical}\n",
      "advantage in doing adaptive AMSDU aggregation based on the link bit error rate.\n",
      "Evaluations on a model show that instead of implementing a complex adaptive\n",
      "AMSDU frame aggregation mechanism which impact queuing and other implementation\n",
      "aspects, it is easier to influence packet error rate with traditional\n",
      "mechanisms while keeping the AMSDU aggregation logic simple.\n",
      "\n",
      "Predicted Category: Mathematics\n",
      "\n",
      "Actual Category: Mathematics\n",
      "\n",
      "Test Sample 4:\n",
      "Title: The $Gaia$-ESO Survey: the inner disk intermediate-age open cluster NGC 6802\n",
      "Abstract:   Milky Way open clusters are very diverse in terms of age, chemical\n",
      "composition, and kinematic properties. Intermediate-age and old open clusters\n",
      "are less common, and it is even harder to find them inside the solar\n",
      "Galactocentric radius, due to the high mortality rate and strong extinction\n",
      "inside this region. NGC 6802 is one of the inner disk open clusters (IOCs)\n",
      "observed by the $Gaia$-ESO survey (GES). This cluster is an important target\n",
      "for calibrating the abundances derived in the survey due to the kinematic and\n",
      "chemical homogeneity of the members in open clusters. Using the measurements\n",
      "from $Gaia$-ESO internal data release 4 (iDR4), we identify 95 main-sequence\n",
      "dwarfs as cluster members from the GIRAFFE target list, and eight giants as\n",
      "cluster members from the UVES target list. The dwarf cluster members have a\n",
      "median radial velocity of $13.6\\pm1.9$ km s$^{-1}$, while the giant cluster\n",
      "members have a median radial velocity of $12.0\\pm0.9$ km s$^{-1}$ and a median\n",
      "[Fe/H] of $0.10\\pm0.02$ dex. The color-magnitude diagram of these cluster\n",
      "members suggests an age of $0.9\\pm0.1$ Gyr, with $(m-M)_0=11.4$ and\n",
      "$E(B-V)=0.86$. We perform the first detailed chemical abundance analysis of NGC\n",
      "6802, including 27 elemental species. To gain a more general picture about\n",
      "IOCs, the measurements of NGC 6802 are compared with those of other IOCs\n",
      "previously studied by GES, that is, NGC 4815, Trumpler 20, NGC 6705, and\n",
      "Berkeley 81. NGC 6802 shows similar C, N, Na, and Al abundances as other IOCs.\n",
      "These elements are compared with nucleosynthetic models as a function of\n",
      "cluster turn-off mass. The $\\alpha$, iron-peak, and neutron-capture elements\n",
      "are also explored in a self-consistent way.\n",
      "\n",
      "Predicted Category: Physics\n",
      "\n",
      "Actual Category: Mathematics\n",
      "\n",
      "Test Sample 5:\n",
      "Title: Witness-Functions versus Interpretation-Functions for Secrecy in Cryptographic Protocols: What to Choose?\n",
      "Abstract:   Proving that a cryptographic protocol is correct for secrecy is a hard task.\n",
      "One of the strongest strategies to reach this goal is to show that it is\n",
      "increasing, which means that the security level of every single atomic message\n",
      "exchanged in the protocol, safely evaluated, never deceases. Recently, two\n",
      "families of functions have been proposed to measure the security level of\n",
      "atomic messages. The first one is the family of interpretation-functions. The\n",
      "second is the family of witness-functions. In this paper, we show that the\n",
      "witness-functions are more efficient than interpretation-functions. We give a\n",
      "detailed analysis of an ad-hoc protocol on which the witness-functions succeed\n",
      "in proving its correctness for secrecy while the interpretation-functions fail\n",
      "to do so.\n",
      "\n",
      "Predicted Category: Computer Science\n",
      "\n",
      "Actual Category: Computer Science\n",
      "\n",
      "Accuracy: 0.239\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ollama\n",
    "\n",
    "# Load the data\n",
    "data_path = 'dataset/research'\n",
    "train_df = pd.read_csv(data_path + '/train.csv')\n",
    "test_df = pd.read_csv(data_path + '/test.csv')\n",
    "\n",
    "# print(train_df.head())\n",
    "# print(test_df.head())\n",
    "\n",
    "train_text = train_df[['TITLE', 'ABSTRACT']]\n",
    "train_labels = train_df[['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']]\n",
    "test_text = test_df[['TITLE', 'ABSTRACT']]\n",
    "\n",
    "labels = []\n",
    "for index, row in train_labels.iterrows():\n",
    "    for i, label in enumerate(row):\n",
    "        if label == 1:\n",
    "            labels.append(train_labels.columns[i])\n",
    "\n",
    "# Function to interact with the Ollama API\n",
    "def get_prediction(title, abstract):\n",
    "    response = ollama.generate(model='llama3', prompt=f\"Title: {title}\\nAbstract:{abstract}\\n {optimized_prompt_response} Only respond with the category name.\")\n",
    "    return response['response']\n",
    "\n",
    "# Predict for the test set\n",
    "test_predictions = []\n",
    "for index, row in train_text.iterrows():\n",
    "    if index % 100 == 0:\n",
    "        print(f\"Predicting for sample {index+1}...\")\n",
    "    if index == 1000:\n",
    "        break\n",
    "    prediction = get_prediction(row['TITLE'], row['ABSTRACT'])\n",
    "    test_predictions.append(prediction)\n",
    "\n",
    "# Display some predictions\n",
    "for i, prediction in enumerate(test_predictions[:5]):\n",
    "    print(f\"Test Sample {i+1}:\")\n",
    "    print(f\"Title: {test_text.iloc[i]['TITLE']}\")\n",
    "    print(f\"Abstract: {test_text.iloc[i]['ABSTRACT']}\")\n",
    "    print(f\"Predicted Category: {prediction}\\n\")\n",
    "    print(f\"Actual Category: {labels[i]}\\n\")\\\n",
    "    \n",
    "# calculate the accuracy\n",
    "correct = 0\n",
    "for i, prediction in enumerate(test_predictions):\n",
    "    if prediction == labels[i]:\n",
    "        correct += 1\n",
    "accuracy = correct / len(test_predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf61d9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sample 6:\n",
      "Title: Pairwise Difference Estimation of High Dimensional Partially Linear Model\n",
      "Abstract:   This paper proposes a regularized pairwise difference approach for estimating\n",
      "the linear component coefficient in a partially linear model, with consistency\n",
      "and exact rates of convergence obtained in high dimensions under mild scaling\n",
      "requirements. Our analysis reveals interesting features such as (i) the\n",
      "bandwidth parameter automatically adapts to the model and is actually\n",
      "tuning-insensitive; and (ii) the procedure could even maintain fast rate of\n",
      "convergence for $\\alpha$-Hlder class of $\\alpha\\leq1/2$. Simulation studies\n",
      "show the advantage of the proposed method, and application of our approach to a\n",
      "brain imaging data reveals some biological patterns which fail to be recovered\n",
      "using competing methods.\n",
      "\n",
      "Predicted Category: Mathematics\n",
      "\n",
      "Actual Category: Statistics\n",
      "\n",
      "Test Sample 7:\n",
      "Title: Dissecting the multivariate extremal index and tail dependence\n",
      "Abstract:   A central issue in the theory of extreme values focuses on suitable\n",
      "conditions such that the well-known results for the limiting distributions of\n",
      "the maximum of i.i.d. sequences can be applied to stationary ones. In this\n",
      "context, the extremal index appears as a key parameter to capture the effect of\n",
      "temporal dependence on the limiting distribution of the maxima. The\n",
      "multivariate extremal index corresponds to a generalization of this concept to\n",
      "a multivariate context and affects the tail dependence structure within the\n",
      "marginal sequences and between them. As it is a function, the inference becomes\n",
      "more difficult, and it is therefore important to obtain characterizations,\n",
      "namely bounds based on the marginal dependence that are easier to estimate. In\n",
      "this work we present two decompositions that emphasize different types of\n",
      "information contained in the multivariate extremal index, an upper limit better\n",
      "than those found in the literature and we analyze its role in dependence on the\n",
      "limiting model of the componentwise maxima of a stationary sequence. We will\n",
      "illustrate the results with examples of recognized interest in applications.\n",
      "\n",
      "Predicted Category: Physics\n",
      "\n",
      "Actual Category: Mathematics\n",
      "\n",
      "Test Sample 10:\n",
      "Title: Properties and Origin of Galaxy Velocity Bias in the Illustris Simulation\n",
      "Abstract:   We use the hydrodynamical galaxy formation simulations from the Illustris\n",
      "suite to study the origin and properties of galaxy velocity bias, i.e., the\n",
      "difference between the velocity distributions of galaxies and dark matter\n",
      "inside halos. We find that galaxy velocity bias is a decreasing function of the\n",
      "ratio of galaxy stellar mass to host halo mass. In general, central galaxies\n",
      "are not at rest with respect to dark matter halos or the core of halos, with a\n",
      "velocity dispersion above 0.04 times that of the dark matter. The central\n",
      "galaxy velocity bias is found to be mostly caused by the close interactions\n",
      "between the central and satellite galaxies. For satellite galaxies, the\n",
      "velocity bias is related to their dynamical and tidal evolution history after\n",
      "being accreted onto the host halos. It depends on the time after the accretion\n",
      "and their distances from the halo centers, with massive satellites generally\n",
      "moving more slowly than the dark matter. The results are in broad agreements\n",
      "with those inferred from modeling small-scale redshift-space galaxy clustering\n",
      "data, and the study can help improve models of redshift-space galaxy\n",
      "clustering.\n",
      "\n",
      "Predicted Category: Quantitative Biology\n",
      "\n",
      "Actual Category: Physics\n",
      "\n",
      "Test Sample 11:\n",
      "Title: Computer Modeling of Halogen Bonds and Other $$-Hole Interactions\n",
      "Abstract:   In the field of noncovalent interactions a new paradigm has recently become\n",
      "popular. It stems from the analysis of molecular electrostatic potentials and\n",
      "introduces a label, which has recently attracted enormous attention. The label\n",
      "is {\\sigma}-hole, and it was first used in connection with halogens. It\n",
      "initiated a renaissance of interest in halogenated compounds, and later on,\n",
      "when found also on other groups of atoms (chalcogens, pnicogens, tetrels and\n",
      "aerogens), it resulted in a new direction of research of intermolecular\n",
      "interactions. In this review, we summarize advances from about the last 10\n",
      "years in understanding those interactions related to {\\sigma}-hole. We pay\n",
      "particular attention to theoretical and computational techniques, which play a\n",
      "crucial role in the field.\n",
      "\n",
      "Predicted Category: Physics\n",
      "\n",
      "Actual Category: Quantitative Biology\n",
      "\n",
      "Test Sample 12:\n",
      "Title: Towards Universal End-to-End Affect Recognition from Multilingual Speech by ConvNets\n",
      "Abstract:   We propose an end-to-end affect recognition approach using a Convolutional\n",
      "Neural Network (CNN) that handles multiple languages, with applications to\n",
      "emotion and personality recognition from speech. We lay the foundation of a\n",
      "universal model that is trained on multiple languages at once. As affect is\n",
      "shared across all languages, we are able to leverage shared information between\n",
      "languages and improve the overall performance for each one. We obtained an\n",
      "average improvement of 12.8% on emotion and 10.1% on personality when compared\n",
      "with the same model trained on each language only. It is end-to-end because we\n",
      "directly take narrow-band raw waveforms as input. This allows us to accept as\n",
      "input audio recorded from any source and to avoid the overhead and information\n",
      "loss of feature extraction. It outperforms a similar CNN using spectrograms as\n",
      "input by 12.8% for emotion and 6.3% for personality, based on F-scores.\n",
      "Analysis of the network parameters and layers activation shows that the network\n",
      "learns and extracts significant features in the first layer, in particular\n",
      "pitch, energy and contour variations. Subsequent convolutional layers instead\n",
      "capture language-specific representations through the analysis of\n",
      "supra-segmental features. Our model represents an important step for the\n",
      "development of a fully universal affect recognizer, able to recognize\n",
      "additional descriptors, such as stress, and for the future implementation into\n",
      "affective interactive systems.\n",
      "\n",
      "Predicted Category: Physics\n",
      "\n",
      "Actual Category: Computer Science\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print some misclassified samples\n",
    "count = 0\n",
    "for i, prediction in enumerate(test_predictions):\n",
    "    if prediction != labels[i]:\n",
    "        print(f\"Test Sample {i+1}:\")\n",
    "        print(f\"Title: {test_text.iloc[i]['TITLE']}\")\n",
    "        print(f\"Abstract: {test_text.iloc[i]['ABSTRACT']}\")\n",
    "        print(f\"Predicted Category: {prediction}\\n\")\n",
    "        print(f\"Actual Category: {labels[i]}\\n\")\n",
    "        count += 1\n",
    "    if count == 5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
